{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "073f4639-6586-4aac-82b9-7c16b8db250f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.path.dirname(os.path.abspath('..')))\n",
    "\n",
    "# CUDA\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dfdc543-3870-415b-9bc9-a9722da7a058",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import date, datetime, timedelta\n",
    "from typing import Tuple, List\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "from AltimeterAutoencoder.src.save_load_model import load_model as load_autoencoder\n",
    "from AltimeterAutoencoder.src.regressor import MetaRegression\n",
    "from AltimeterAutoencoder.src import _types\n",
    "from AltimeterAutoencoder.src.regressor import fit_regressor, MetaRegression\n",
    "from Models.AttentionConvLSTMAutoEncoder import SaveLoadModels\n",
    "from Models.AttentionConvLSTMAutoEncoder.training_loop import train_validation_loop\n",
    "from Models.AttentionConvLSTMAutoEncoder.Seq2SeqAttention import Seq2SeqAttention, InputModel, OutputModel\n",
    "from Models.Shared import Loss, DatasetParameters\n",
    "from Models.Shared.Dataloader import SLADataset\n",
    "from Models.AttentionConvLSTM import Attention, Encoder, Decoder\n",
    "from Models.AttentionConvLSTM.Loss import create_masked_loss_function_diff\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "def print_to_file_on_epoch(loss: Loss, _: _types.float_like, __: _types.float_like, n_epochs: int):\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.info(f\"Epoch: {loss.epoch:04d}/{n_epochs} Training Loss: {loss.training_loss:.7f} Validation Loss: {loss.validation_loss:.7f}\")\n",
    "\n",
    "def setup_model(\n",
    "    in_channels: int,\n",
    "    encoder_in_channels: int,\n",
    "    encoder_out_channels: int,\n",
    "    kernel_size: Tuple[int, int],\n",
    "    padding: Tuple[int, int],\n",
    "    frame_size: Tuple[int, int],\n",
    "    hidden_output_network_channels: List[int]\n",
    ") -> Seq2SeqAttention:\n",
    "    # Construct models\n",
    "    input_model = InputModel(in_channels, encoder_in_channels)\n",
    "\n",
    "    encoder = Encoder(\n",
    "        in_channels = encoder_in_channels,\n",
    "        out_channels = encoder_out_channels,\n",
    "        kernel_size = kernel_size,\n",
    "        padding = padding,\n",
    "        activation = nn.Tanh(),\n",
    "        frame_size = frame_size,\n",
    "    )\n",
    "\n",
    "    attention = Attention(encoder_out_channels, encoder_out_channels)\n",
    "\n",
    "    decoder = Decoder(\n",
    "        in_channels = encoder_in_channels,\n",
    "        hidden_channels = encoder_out_channels,\n",
    "        out_channels = encoder_out_channels,\n",
    "        kernel_size = kernel_size,\n",
    "        padding = padding,\n",
    "        activation = nn.Tanh(),\n",
    "        frame_size = frame_size,\n",
    "        attention = attention\n",
    "    )\n",
    "\n",
    "    output_network = OutputModel(\n",
    "        in_channels = decoder.resulting_channels,\n",
    "        hidden_channels = hidden_output_network_channels,\n",
    "        output_channels = in_channels\n",
    "    )\n",
    "    return Seq2SeqAttention(input_model, encoder, decoder, output_network)\n",
    "\n",
    "def load_model(\n",
    "    model_path: Path,\n",
    "    device: torch.device,\n",
    "    regressor_path: Path\n",
    ") -> Tuple[Seq2SeqAttention, torch.optim.Optimizer, Loss, DatasetParameters, MetaRegression, int, str]:\n",
    "    model, optimizer, last_loss, dataset_parameters, auto_encoder_name = SaveLoadModels.load_checkpoint(\n",
    "        model_path,\n",
    "        Seq2SeqAttention,\n",
    "        device\n",
    "    )\n",
    "    with open(regressor_path, 'rb') as file:\n",
    "        regressor = MetaRegression.load(file)\n",
    "    start_epoch = last_loss.epoch\n",
    "    return model, optimizer, last_loss, dataset_parameters, regressor, start_epoch, auto_encoder_name\n",
    "\n",
    "def setup_data(\n",
    "    datapath: Path,\n",
    "    save_path: Path,\n",
    "    dataset_parameters: DatasetParameters,\n",
    "    regressor: MetaRegression | None = None\n",
    ") -> Tuple[DataLoader[SLADataset], DataLoader[SLADataset]]:\n",
    "    with xr.open_dataset(datapath, engine=\"netcdf4\") as file:\n",
    "        file = file.sortby('time')\n",
    "        sla = file['sla21'].data[:, :-1]\n",
    "        times: _types.time_like = file['time'].data\n",
    "\n",
    "    # Set train, validation and test intervals\n",
    "    train_start_np = np.array(dataset_parameters.train_start).astype(\"datetime64[ns]\")\n",
    "    train_end = np.array(dataset_parameters.train_end).astype(\"datetime64[ns]\")\n",
    "    validation_end = np.array(dataset_parameters.validation_end).astype(\"datetime64[ns]\")\n",
    "\n",
    "    # Save times\n",
    "    bool_train = (times > train_start_np) & (times <= train_end)\n",
    "    bool_validation = (times > train_end) & (times <= validation_end)\n",
    "\n",
    "    if regressor is None:\n",
    "        regressor = fit_regressor(times[bool_train], sla[bool_train], save_path)\n",
    "\n",
    "    sla -= regressor.predict(times).reshape(*sla.shape)\n",
    "    train_time: _types.int_like = times[bool_train].astype(\"datetime64[D]\").astype(int)\n",
    "    validation_time: _types.int_like = times[bool_validation].astype(\"datetime64[D]\").astype(int)\n",
    "\n",
    "    # Save sla features\n",
    "    train_features = sla[bool_train]\n",
    "    validation_features = sla[bool_validation]\n",
    "\n",
    "    # Kwargs to dataloaders\n",
    "    kwargs_dataloader = {\n",
    "        'shuffle': False,\n",
    "        'batch_size': dataset_parameters.batch_size\n",
    "    }\n",
    "\n",
    "    # Dataloders\n",
    "    train_loader = DataLoader(SLADataset(train_features, train_time, dataset_parameters), **kwargs_dataloader)\n",
    "    validation_loader = DataLoader(SLADataset(validation_features, validation_time, dataset_parameters), **kwargs_dataloader)\n",
    "    return train_loader, validation_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85062045-2af6-4baa-a61b-f8632c024595",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "extent = [-179.5, 179.5, -64.5, 62.5]\n",
    "def setup_plot_on_epoch(print_to_file: bool = True, day_number: int = 29):\n",
    "    losses = []\n",
    "    epochs = []\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    times = []\n",
    "    \n",
    "    fig, axs = plt.subplots(4, 2, figsize=(14, 21))\n",
    "    gs_true = axs[2, 0].get_gridspec()\n",
    "    gs_pred = axs[3, 0].get_gridspec()\n",
    "\n",
    "    # remove the underlying axes\n",
    "    for ax in axs[2:, :].flatten():\n",
    "        ax.remove()\n",
    "    ax_example_img_true = fig.add_subplot(gs_true[2, :])\n",
    "    ax_example_img_pred = fig.add_subplot(gs_pred[3, :])\n",
    "    ((ax_epoch, ax_epoch_all), (ax_learningrate, ax_time)) = axs[:2, :]\n",
    "    \n",
    "    def update_line(loss, example_img_true, example_img_pred, total_epochs):\n",
    "        # try:\n",
    "        if print_to_file:\n",
    "            print_to_file_on_epoch(loss, example_img_true, example_img_pred, total_epochs)\n",
    "\n",
    "        losses.append(loss)\n",
    "        train_loss.append(loss.training_loss)\n",
    "        val_loss.append(loss.validation_loss)\n",
    "        epochs.append(loss.epoch)\n",
    "\n",
    "        if len(losses) > 1:\n",
    "            total_seconds = (loss.time - losses[-2].time).total_seconds()/60\n",
    "            estimated_next_epoch = datetime.now() + timedelta(seconds=total_seconds)\n",
    "            times.append(total_seconds)\n",
    "            fig.suptitle(f\"Estimated time left: {total_seconds/60 * (total_epochs - loss.epoch):.2f} h\\nEstimated next epoch: {estimated_next_epoch.strftime('%H:%M:%S')}\")\n",
    "            ax_time.plot(epochs[1:], times, color='red')\n",
    "\n",
    "        ax_epoch.plot(epochs, train_loss, color='red', label=\"Training\")\n",
    "        ax_epoch.plot(epochs, val_loss, color='blue', label=\"Validation\")\n",
    "        ax_epoch.set_ylim([min(train_loss[-1], val_loss[-1])*0.9, max(train_loss[-1], val_loss[-1])*1.1])\n",
    "\n",
    "        ax_epoch_all.plot(epochs, train_loss, color='red', label=\"Training\")\n",
    "        ax_epoch_all.plot(epochs, val_loss, color='blue', label=\"Validation\")        \n",
    "\n",
    "        im_pred = ax_example_img_pred.imshow(example_img_pred[day_number], extent=extent, vmin=-0.7, vmax=0.7, origin='lower', cmap='jet')\n",
    "        im_true = ax_example_img_true.imshow(example_img_true[day_number], extent=extent, vmin=-0.7, vmax=0.7, origin='lower', cmap='jet')\n",
    "\n",
    "\n",
    "        if len(epochs) == 1:\n",
    "            ax_epoch.set_title(f\"Loss\")\n",
    "            ax_epoch.legend(loc='upper right')\n",
    "            ax_epoch.set_xlabel(\"Epoch\")\n",
    "            ax_epoch.set_ylabel(\"Loss\")\n",
    "            ax_epoch.grid()\n",
    "\n",
    "            ax_epoch_all.set_title(f\"Loss\")\n",
    "            ax_epoch_all.legend(loc='upper right')\n",
    "            ax_epoch_all.set_xlabel(\"Epoch\")\n",
    "            ax_epoch_all.set_ylabel(\"Loss\")\n",
    "            ax_epoch_all.grid()\n",
    "\n",
    "            ax_time.set_xlabel(\"Epoch\")\n",
    "            ax_time.set_ylabel(\"Time [Minutes]\")\n",
    "            ax_time.grid()\n",
    "\n",
    "            ax_learningrate.set_xlabel(\"Epoch\")\n",
    "            ax_learningrate.set_ylabel(\"Learning rate\")\n",
    "            ax_learningrate.grid()\n",
    "\n",
    "            ax_example_img_true.set_title(f\"True image {day_number + 1} days\")\n",
    "            ax_example_img_true.set_xlabel(\"Lon\")\n",
    "            ax_example_img_true.set_ylabel(\"Lat\")\n",
    "\n",
    "            ax_example_img_pred.set_title(f\"Prediction {day_number + 1} days\")\n",
    "            ax_example_img_pred.set_xlabel(\"Lon\")\n",
    "            ax_example_img_pred.set_ylabel(\"Lat\")\n",
    "            plt.colorbar(im_true, ax = ax_example_img_true)\n",
    "            plt.colorbar(im_pred, ax = ax_example_img_pred)\n",
    "\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())\n",
    "        # except:\n",
    "        #     pass\n",
    "    return update_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74d12d94-dafc-4762-b9b3-069b4cf9340f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATAPATH = Path(r\"Data/Grids/without_polar_v5_mss21.nc\")\n",
    "SAVEFOLDER = Path(\"SavedModels\", \"ConvLSTMAttentionEncDec\")\n",
    "AUTOENCODERFOLDER = Path(\"SavedModels\", \"autoencoder_checkpoints\")\n",
    "auto_encoder_name = \"checkpoint_1000epochs_128channels_unmasked.pkl\"\n",
    "MODEL_NAME = \"checkpoint_20.pkl\"\n",
    "SAVEFOLDER.mkdir(parents=True, exist_ok=True)\n",
    "LOAD_MODEL = False\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "stream_handler = logging.StreamHandler(sys.stdout)\n",
    "formatter = logging.Formatter('%(asctime)s:%(message)s')\n",
    "stream_handler.setFormatter(formatter)\n",
    "stream_handler.setLevel(logging.DEBUG)\n",
    "\n",
    "file_handler = logging.FileHandler('log.log')\n",
    "file_handler.setFormatter(formatter)\n",
    "file_handler.setLevel(logging.DEBUG)\n",
    "\n",
    "logger.addHandler(stream_handler)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "\n",
    "\n",
    "# Dataset parameters\n",
    "default_batch_size = 6\n",
    "default_sequence_length = 30\n",
    "default_sequence_steps = 1\n",
    "default_prediction_steps = 1\n",
    "default_n_predictions = 30\n",
    "\n",
    "# Model parameters\n",
    "kernel_size = (3, 3)\n",
    "padding = ((kernel_size[0] - 1)//2, (kernel_size[1] - 1)//2)\n",
    "frame_size = (128, 360)\n",
    "encoder_in_channels = 128\n",
    "encoder_out_channels = 128\n",
    "hidden_output_network_channels = [128, 128]\n",
    "\n",
    "# Training loop\n",
    "learning_rate = 1e-6 #1e-5\n",
    "weight_decay = 0\n",
    "epochs = 100\n",
    "save_every = 10\n",
    "n_sequences = 30\n",
    "scheduler = None\n",
    "teacher_forcing_ratio_list: List[float] = [0]*epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e06bd9db-6109-425d-8e18-d7912dbe2df2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loss\n",
    "criterion = create_masked_loss_function_diff(nn.MSELoss)\n",
    "\n",
    "regressor = None\n",
    "if LOAD_MODEL:\n",
    "    model, optimizer, last_loss, dataset_parameters, regressor, start_epoch, auto_encoder_name = load_model(\n",
    "        SAVEFOLDER / MODEL_NAME,\n",
    "        DEVICE,\n",
    "        SAVEFOLDER / \"Regression.pkl\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f3846eb-ca3d-4502-8268-4f1937ab2530",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load autoencoder\n",
    "encoder, decoder, _, _, _, fill_nan, _, train_start, train_end, validation_end = load_autoencoder(\n",
    "    AUTOENCODERFOLDER / auto_encoder_name,\n",
    "    DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07aa6247-e24d-440b-968d-2a55d7c0aebf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not LOAD_MODEL:\n",
    "    dataset_parameters = DatasetParameters(\n",
    "        batch_size = default_batch_size,\n",
    "        sequence_length = default_sequence_length,\n",
    "        sequence_steps = default_sequence_steps,\n",
    "        prediction_steps = default_prediction_steps,\n",
    "        fill_nan = fill_nan,\n",
    "        train_start = train_start,\n",
    "        train_end = train_end,\n",
    "        validation_end = validation_end,\n",
    "        n_predictions = default_n_predictions,\n",
    "    )\n",
    "    start_epoch = 0\n",
    "\n",
    "    model = setup_model(\n",
    "        in_channels = encoder.feature_dimension,\n",
    "        encoder_in_channels = encoder_in_channels,\n",
    "        encoder_out_channels = encoder_out_channels,\n",
    "        kernel_size = kernel_size,\n",
    "        padding = padding,\n",
    "        frame_size = encoder.get_out_frame_size(frame_size),\n",
    "        hidden_output_network_channels = []\n",
    "    ).to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "with open(SAVEFOLDER / \"Regression.pkl\", 'rb') as file:\n",
    "    regressor = MetaRegression.load(file)\n",
    "    \n",
    "train_loader, validation_loader = setup_data(\n",
    "    DATAPATH,\n",
    "    SAVEFOLDER / \"Regression.pkl\",\n",
    "    dataset_parameters, # type: ignore\n",
    "    regressor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e06046a-8094-4178-b5cc-fbbf33e42d2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed 16 times\r"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "for i in range(100):\n",
    "    try:\n",
    "        scheduler = None\n",
    "        losses = train_validation_loop(\n",
    "            encoder = encoder,\n",
    "            decoder = decoder,\n",
    "            model = model, # type: ignore\n",
    "            train_loader = train_loader,\n",
    "            val_loader = validation_loader,\n",
    "            criterion = criterion,\n",
    "            optimizer = optimizer, # type: ignore\n",
    "            num_epochs = epochs,\n",
    "            start_epoch = start_epoch, # type: ignore\n",
    "            device = DEVICE,\n",
    "            update_function = setup_plot_on_epoch(True, 29),\n",
    "            path = SAVEFOLDER,\n",
    "            save_n_epochs = save_every,\n",
    "            dataset_parameters = dataset_parameters, # type: ignore\n",
    "            teacher_forcing_ratios = teacher_forcing_ratio_list,\n",
    "            losses = None,\n",
    "            scheduler = scheduler,\n",
    "            n_sequences = n_sequences,\n",
    "            encoder_filename = auto_encoder_name\n",
    "        )\n",
    "        plt.close()\n",
    "        break\n",
    "    except ValueError:\n",
    "        plt.close()\n",
    "        model = setup_model(\n",
    "            in_channels = encoder.feature_dimension,\n",
    "            encoder_in_channels = encoder_in_channels,\n",
    "            encoder_out_channels = encoder_out_channels,\n",
    "            kernel_size = kernel_size,\n",
    "            padding = padding,\n",
    "            frame_size = encoder.get_out_frame_size(frame_size),\n",
    "            hidden_output_network_channels = hidden_output_network_channels\n",
    "        ).to(DEVICE)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        print(f\"{datetime.now()} | Failed {i} times\", end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faf94e9-2e59-4567-8918-53ce6079558c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    while True:\n",
    "        features, target, mask, _, result_time = next(iter(validation_loader))\n",
    "        # Save time\n",
    "        batch_size = result_time.size(0)\n",
    "        target_times = result_time.numpy()\n",
    "\n",
    "        if torch.any(torch.all(torch.all(mask, dim=3), dim=2)):\n",
    "            continue\n",
    "\n",
    "        # Move to device\n",
    "        features = features.to(DEVICE)\n",
    "        target = target.to(DEVICE)\n",
    "        mask = mask.to(DEVICE)\n",
    "\n",
    "        # Predict\n",
    "        latent_space, output = model.get_latent_space(encoder, decoder, features, None, n_sequences, 0)\n",
    "        target = target.squeeze(1)\n",
    "        output[mask] = np.nan\n",
    "        target[mask] = np.nan\n",
    "        output = output.detach().cpu().numpy()\n",
    "        target = target.detach().cpu().numpy()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3100a198-3f25-44dc-8cf3-6d5027268707",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "latent_space = latent_space.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b391c1-b844-4815-83a7-1efc50e7220a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_id = 0\n",
    "channel_id = 0\n",
    "day_id = 29\n",
    "plt.figure(figsize=(14,4))\n",
    "plt.imshow(latent_space[batch_id, channel_id, day_id], origin='lower', cmap='jet')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "plt.figure(figsize=(14,4))\n",
    "plt.imshow(output[batch_id, day_id], origin='lower', cmap='jet')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c7861f-2b16-40d7-93b4-5a8fae442928",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cmcrameri.cm as cmc\n",
    "\n",
    "def get_pred_title_multi(dataset_parameters: DatasetParameters, n_predictions: int):\n",
    "    return f\"{n_predictions * dataset_parameters.prediction_steps} days predictions using {dataset_parameters.sequence_length} day(s) of data\\nwith {dataset_parameters.sequence_steps - 1} day(s) inbetween\"\n",
    "\n",
    "def get_pred_title(dataset_parameters: DatasetParameters, n_predictions: int):\n",
    "    return get_pred_title_multi(dataset_parameters, n_predictions).replace('\\n', ' ')\n",
    "\n",
    "idx = 0\n",
    "day_prediction = 29\n",
    "\n",
    "vmin = -0.75\n",
    "vmax = 0.75\n",
    "cmap = 'jet'\n",
    "\n",
    "vmin_diff = -0.3\n",
    "vmax_diff = 0.3\n",
    "\n",
    "diffs = target - output\n",
    "diff_data = diffs[idx, day_prediction]\n",
    "diff_vector = diff_data[~np.isnan(diff_data)].flatten()\n",
    "rmse = np.sqrt(diff_vector @ diff_vector / len(diff_vector))\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(16,10))\n",
    "im_target = axes[0].imshow(target[idx, day_prediction], origin='lower', extent=extent, vmin=vmin, vmax=vmax, cmap=cmap)\n",
    "im_pred = axes[1].imshow(output[idx, day_prediction], origin='lower', extent=extent, vmin=vmin, vmax=vmax, cmap=cmap)\n",
    "im_diff = axes[2].imshow(diff_data, origin='lower', extent=extent, vmin=vmin_diff, vmax=vmax_diff, cmap=cmap)\n",
    "\n",
    "axes[0].set_title(f\"Target {target_times[idx, day_prediction]} (Validation set)\")\n",
    "axes[1].set_title(get_pred_title(dataset_parameters, day_prediction + 1))\n",
    "axes[2].set_title(f\"Target - Prediction (RMSE = {rmse*100:.2f}cm)\")\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    ax.set_ylabel(\"Latitude\")\n",
    "    ax.set_xlabel(\"Longitude\")\n",
    "\n",
    "caxs = []\n",
    "caxs.append(fig.colorbar(im_target))\n",
    "caxs.append(fig.colorbar(im_pred))\n",
    "caxs.append(fig.colorbar(im_diff))\n",
    "\n",
    "for cax in caxs:\n",
    "    cax.ax.set_ylabel(\"SLA [m]\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeee5773-2f67-41c5-81e1-89d7520024a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
