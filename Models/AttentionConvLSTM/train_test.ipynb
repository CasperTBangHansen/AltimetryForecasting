{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "073f4639-6586-4aac-82b9-7c16b8db250f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.path.dirname(os.path.abspath('..')))\n",
    "\n",
    "device_ids = [3]\n",
    "\n",
    "# CUDA\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ','.join(map(str, device_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dfdc543-3870-415b-9bc9-a9722da7a058",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import date, datetime, timedelta\n",
    "from typing import Tuple, List\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import cmcrameri.cm as cmc\n",
    "\n",
    "\n",
    "from AltimeterAutoencoder.src import _types\n",
    "from AltimeterAutoencoder.src.regressor import fit_regressor, MetaRegression\n",
    "from Models.AttentionConvLSTM import SaveLoadModels\n",
    "from Models.AttentionConvLSTM.training_loop import train_validation_loop\n",
    "from Models.AttentionConvLSTM.Seq2SeqAttention import Seq2SeqAttention, InputModel, OutputModel\n",
    "from Models.Shared import Loss, DatasetParameters\n",
    "from Models.Shared.Dataloader import SLADataset\n",
    "from Models.AttentionConvLSTM import Attention, Encoder, Decoder\n",
    "from Models.AttentionConvLSTM.Loss import create_masked_loss_function_diff\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def print_to_file_on_epoch(loss: Loss, _: _types.float_like, __: _types.float_like, train_mse_losses, train_grad_losses, val_mse_losses, val_grad_losses, n_epochs: int):\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.info(f\"Epoch: {loss.epoch:04d}/{n_epochs} Training Loss: {loss.training_loss:.7f} Validation Loss: {loss.validation_loss:.7f}\")\n",
    "    \n",
    "    logger = logging.getLogger(\"MSE\")\n",
    "    logger.info(f\"Epoch: {loss.epoch:04d}/{n_epochs} | Train: {','.join(train_mse_losses.astype(str))} | Validation: {','.join(val_mse_losses.astype(str))}\")\n",
    "    \n",
    "    logger = logging.getLogger(\"GRAD_MSE\")\n",
    "    logger.info(f\"Epoch: {loss.epoch:04d}/{n_epochs} | Train: {','.join(train_grad_losses.astype(str))} | Validation: {','.join(val_grad_losses.astype(str))}\")\n",
    "\n",
    "def setup_model(\n",
    "    in_channels: int,\n",
    "    encoder_in_channels: int,\n",
    "    encoder_out_channels: int,\n",
    "    kernel_size: Tuple[int, int],\n",
    "    padding: Tuple[int, int],\n",
    "    frame_size: Tuple[int, int],\n",
    "    hidden_output_network_channels: List[int]\n",
    ") -> Seq2SeqAttention:\n",
    "    # Construct models\n",
    "    input_model = InputModel(in_channels, encoder_in_channels)\n",
    "\n",
    "    encoder = Encoder(\n",
    "        in_channels = encoder_in_channels,\n",
    "        out_channels = encoder_out_channels,\n",
    "        kernel_size = kernel_size,\n",
    "        padding = padding,\n",
    "        activation = nn.Tanh(),\n",
    "        frame_size = frame_size,\n",
    "    )\n",
    "\n",
    "    attention = Attention(encoder_out_channels, encoder_out_channels)\n",
    "\n",
    "    decoder = Decoder(\n",
    "        in_channels = encoder_in_channels,\n",
    "        hidden_channels = encoder_out_channels,\n",
    "        out_channels = encoder_out_channels,\n",
    "        kernel_size = kernel_size,\n",
    "        padding = padding,\n",
    "        activation = nn.Tanh(),\n",
    "        frame_size = frame_size,\n",
    "        attention = attention\n",
    "    )\n",
    "\n",
    "    output_network = OutputModel(\n",
    "        in_channels = decoder.resulting_channels,\n",
    "        hidden_channels = hidden_output_network_channels,\n",
    "        output_channels = in_channels\n",
    "    )\n",
    "    return Seq2SeqAttention(input_model, encoder, decoder, output_network)\n",
    "\n",
    "def load_model(\n",
    "    model_path: Path,\n",
    "    device: torch.device,\n",
    "    regressor_path: Path\n",
    ") -> Tuple[Seq2SeqAttention, torch.optim.Optimizer, Loss, DatasetParameters, MetaRegression, int, str]:\n",
    "    model, optimizer, last_loss, dataset_parameters = SaveLoadModels.load_checkpoint(\n",
    "        model_path,\n",
    "        Seq2SeqAttention,\n",
    "        device\n",
    "    )\n",
    "    with open(regressor_path, 'rb') as file:\n",
    "        regressor = MetaRegression.load(file)\n",
    "    start_epoch = last_loss.epoch\n",
    "    return model, optimizer, last_loss, dataset_parameters, regressor, start_epoch\n",
    "\n",
    "def setup_data(\n",
    "    datapath: Path,\n",
    "    save_path: Path,\n",
    "    dataset_parameters: DatasetParameters,\n",
    "    regressor: MetaRegression | None = None\n",
    ") -> Tuple[DataLoader[SLADataset], DataLoader[SLADataset]]:\n",
    "    with xr.open_dataset(DATAPATH, engine=\"netcdf4\") as file:\n",
    "        file = file.sortby('time')\n",
    "        sla = file['sla21'][:, :-1][:, 20:40, 185:225].data\n",
    "        times: _types.time_like = file['time'].data\n",
    "\n",
    "    # Set train, validation and test intervals\n",
    "    train_start_np = np.array(dataset_parameters.train_start).astype(\"datetime64[ns]\")\n",
    "    train_end = np.array(dataset_parameters.train_end).astype(\"datetime64[ns]\")\n",
    "    validation_end = np.array(dataset_parameters.validation_end).astype(\"datetime64[ns]\")\n",
    "\n",
    "    # Save times\n",
    "    bool_train = (times > train_start_np) & (times <= train_end)\n",
    "    bool_validation = (times > train_end) & (times <= validation_end)\n",
    "\n",
    "    if regressor is None:\n",
    "        regressor = fit_regressor(times[bool_train], sla[bool_train], save_path)\n",
    "\n",
    "    sla -= regressor.predict(times).reshape(*sla.shape)\n",
    "    train_time: _types.int_like = times[bool_train].astype(\"datetime64[D]\").astype(int)\n",
    "    validation_time: _types.int_like = times[bool_validation].astype(\"datetime64[D]\").astype(int)\n",
    "\n",
    "    # Save sla features\n",
    "    train_features = sla[bool_train]\n",
    "    validation_features = sla[bool_validation]\n",
    "\n",
    "    # Kwargs to dataloaders\n",
    "    kwargs_dataloader = {\n",
    "        'shuffle': False,\n",
    "        'batch_size': dataset_parameters.batch_size\n",
    "    }\n",
    "\n",
    "    # Dataloders\n",
    "    train_loader = DataLoader(SLADataset(train_features, train_time, dataset_parameters), **kwargs_dataloader)\n",
    "    validation_loader = DataLoader(SLADataset(validation_features, validation_time, dataset_parameters), **kwargs_dataloader)\n",
    "    return train_loader, validation_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85062045-2af6-4baa-a61b-f8632c024595",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PlotOnEpoch:\n",
    "    def __init__(\n",
    "        self,\n",
    "        print_to_file: bool = True,\n",
    "        day_number_first: int = 0,\n",
    "        day_number_second: int = 29,\n",
    "        plot_every: int = 5\n",
    "    ):\n",
    "        self.plot_every = plot_every\n",
    "        self.extent = [5.5, 44.5, -44.5, -25.5]\n",
    "        self.print_to_file = print_to_file\n",
    "        self.day_number_first = day_number_first\n",
    "        self.day_number_second = day_number_second\n",
    "        self.losses = []\n",
    "        self.epochs = []\n",
    "        self.train_loss = []\n",
    "        self.val_loss = []\n",
    "        self.times = []\n",
    "        self.train_mse_losses = None\n",
    "        self.validation_mse_losses = None\n",
    "        self.fig, self.axes = plt.subplots(5, 2, figsize=(14, 26))\n",
    "        self._no_title = True\n",
    "        self.total_epochs = 0\n",
    "        self.example_images_truth = []\n",
    "        self.example_images_pred = []\n",
    "    \n",
    "        self.ax_epoch = self.axes[0, 0]\n",
    "        self.ax_epoch_all = self.axes[0, 1]\n",
    "\n",
    "        self.ax_epoch_train_color = self.axes[1, 0]\n",
    "        self.ax_epoch_val_color = self.axes[1, 1]\n",
    "\n",
    "        self.ax_learningrate = self.axes[2, 0]\n",
    "        self.ax_time = self.axes[2, 1]\n",
    "\n",
    "        self.ax_example_img_true_first = self.axes[3, 0]\n",
    "        self.ax_example_img_pred_first = self.axes[3, 1]\n",
    "\n",
    "        self.ax_example_img_true_second = self.axes[4, 0]\n",
    "        self.ax_example_img_pred_second = self.axes[4, 1]\n",
    "    \n",
    "    def __call__(self, loss, example_img_true, example_img_pred, train_mse_loss, train_grad_loss, val_mse_loss, val_grad_loss, total_epochs):\n",
    "        if self.print_to_file:\n",
    "            print_to_file_on_epoch(loss, example_img_true, example_img_pred, train_mse_loss, train_grad_loss, val_mse_loss, val_grad_loss, total_epochs)\n",
    "        \n",
    "        if self.train_mse_losses is None:\n",
    "            self.train_mse_losses = train_mse_loss[np.newaxis,:]\n",
    "        else:\n",
    "            self.train_mse_losses = np.vstack([self.train_mse_losses, train_mse_loss])\n",
    "        \n",
    "        if self.validation_mse_losses is None:\n",
    "            self.validation_mse_losses = val_mse_loss[np.newaxis,:]\n",
    "        else:\n",
    "            self.validation_mse_losses = np.vstack([self.validation_mse_losses, val_mse_loss])\n",
    "\n",
    "        self.total_epochs = total_epochs\n",
    "        self.example_images_truth.append(\n",
    "            (example_img_true[self.day_number_first], example_img_true[self.day_number_second])\n",
    "        )\n",
    "        self.example_images_pred.append(\n",
    "            (example_img_pred[self.day_number_first], example_img_pred[self.day_number_second])\n",
    "        )\n",
    "        self.losses.append(loss)\n",
    "        self.train_loss.append(loss.training_loss)\n",
    "        self.val_loss.append(loss.validation_loss)\n",
    "        self.epochs.append(loss.epoch)\n",
    "\n",
    "        if len(self.losses) > 1:\n",
    "            total_seconds = (loss.time - self.losses[-2].time).total_seconds()/60\n",
    "            self.times.append(total_seconds)\n",
    "        \n",
    "        if loss.epoch % self.plot_every == 0:\n",
    "            self.update_figure()\n",
    "    \n",
    "    def update_figure(self, update_title: bool = False):\n",
    "        \n",
    "        if len(self.losses) > 1:\n",
    "            total_seconds = self.times[-1]\n",
    "            estimated_next_epoch = datetime.now() + timedelta(seconds=total_seconds*60)\n",
    "            self.fig.suptitle(f\"Estimated time left: {total_seconds/60 * (self.total_epochs - self.losses[-1].epoch):.2f} h\\nEstimated next epoch: {estimated_next_epoch.strftime('%H:%M:%S')}\")\n",
    "            self.ax_time.plot(self.epochs[1:], self.times, color='red')\n",
    "        \n",
    "        self.ax_epoch.plot(self.epochs, self.train_loss, color='red', label=\"Training\")\n",
    "        self.ax_epoch.plot(self.epochs, self.val_loss, color='blue', label=\"Validation\")\n",
    "        self.ax_epoch.set_ylim([min(self.train_loss[-1], self.val_loss[-1])*0.9, max(self.train_loss[-1], self.val_loss[-1])*1.1])\n",
    "        self.ax_epoch_all.plot(self.epochs, self.train_loss, color='red', label=\"Training\")\n",
    "        self.ax_epoch_all.plot(self.epochs, self.val_loss, color='blue', label=\"Validation\")        \n",
    "\n",
    "        vmin = 0\n",
    "        vmax = 6\n",
    "        train_cbar = self.ax_epoch_train_color.imshow(self.train_mse_losses.T, vmin=vmin, vmax=vmax, origin='lower', cmap='jet', interpolation=\"nearest\", aspect='auto')\n",
    "        val_cbar = self.ax_epoch_val_color.imshow(self.validation_mse_losses.T, vmin=vmin, vmax=vmax, origin='lower', cmap='jet', interpolation=\"nearest\", aspect='auto')\n",
    "\n",
    "        im_pred_first = self.ax_example_img_pred_first.imshow(self.example_images_pred[-1][0] * 100, extent=self.extent, vmin=-50, vmax=50, origin='lower', cmap=cmc.vik)\n",
    "        im_true_first = self.ax_example_img_true_first.imshow(self.example_images_truth[-1][0] * 100, extent=self.extent, vmin=-50, vmax=50, origin='lower', cmap=cmc.vik)\n",
    "\n",
    "        im_pred_second = self.ax_example_img_pred_second.imshow(self.example_images_pred[-1][1] * 100, extent=self.extent, vmin=-50, vmax=50, origin='lower', cmap=cmc.vik)\n",
    "        im_true_second = self.ax_example_img_true_second.imshow(self.example_images_truth[-1][1] * 100, extent=self.extent, vmin=-50, vmax=50, origin='lower', cmap=cmc.vik)\n",
    "        \n",
    "\n",
    "        if self._no_title or update_title:\n",
    "            self._no_title = False\n",
    "            self.ax_epoch_train_color.set_title(\"Training loss for each day\")\n",
    "            self.ax_epoch_train_color.set_xlabel(\"Epoch\")\n",
    "            self.ax_epoch_train_color.set_ylabel(\"Day #\")\n",
    "            \n",
    "            self.ax_epoch_val_color.set_title(\"Validation loss for each day\")\n",
    "            self.ax_epoch_val_color.set_xlabel(\"Epoch\")\n",
    "            self.ax_epoch_val_color.set_ylabel(\"Day #\")\n",
    "            \n",
    "            self.ax_epoch.set_title(f\"Loss\")\n",
    "            self.ax_epoch.legend(loc='upper right')\n",
    "            self.ax_epoch.set_xlabel(\"Epoch\")\n",
    "            self.ax_epoch.set_ylabel(\"Loss\")\n",
    "            self.ax_epoch.grid()\n",
    "\n",
    "            self.ax_epoch_all.set_title(f\"Loss\")\n",
    "            self.ax_epoch_all.legend(loc='upper right')\n",
    "            self.ax_epoch_all.set_xlabel(\"Epoch\")\n",
    "            self.ax_epoch_all.set_ylabel(\"Loss\")\n",
    "            self.ax_epoch_all.grid()\n",
    "\n",
    "            self.ax_time.set_xlabel(\"Epoch\")\n",
    "            self.ax_time.set_ylabel(\"Time [Minutes]\")\n",
    "            self.ax_time.grid()\n",
    "\n",
    "            self.ax_learningrate.set_xlabel(\"Epoch\")\n",
    "            self.ax_learningrate.set_ylabel(\"Learning rate\")\n",
    "            self.ax_learningrate.grid()\n",
    "\n",
    "            for ax in [\n",
    "                self.ax_example_img_true_first,\n",
    "                self.ax_example_img_pred_first,\n",
    "                self.ax_example_img_true_first,\n",
    "                self.ax_example_img_pred_first\n",
    "            ]:\n",
    "                ax.set_xlabel(\"Lon\")\n",
    "                ax.set_ylabel(\"Lat\")\n",
    "            \n",
    "            self.ax_example_img_true_first.set_title(f\"True image {self.day_number_first + 1} days\")\n",
    "            self.ax_example_img_pred_first.set_title(f\"Prediction {self.day_number_first + 1} days\")\n",
    "            self.ax_example_img_true_second.set_title(f\"True image {self.day_number_second + 1} days\")\n",
    "            self.ax_example_img_pred_second.set_title(f\"Prediction {self.day_number_second + 1} days\")\n",
    "\n",
    "            plt.colorbar(im_true_first, ax = self.ax_example_img_true_first)\n",
    "            plt.colorbar(im_pred_first, ax = self.ax_example_img_pred_first)\n",
    "            plt.colorbar(im_true_second, ax = self.ax_example_img_true_second)\n",
    "            plt.colorbar(im_pred_second, ax = self.ax_example_img_pred_second)\n",
    "            plt.colorbar(train_cbar, ax=self.ax_epoch_train_color)\n",
    "            plt.colorbar(val_cbar, ax=self.ax_epoch_val_color)\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74d12d94-dafc-4762-b9b3-069b4cf9340f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATAPATH = Path(r\"Data/Grids/without_polar_v5_mss21.nc\")\n",
    "SAVEFOLDER = Path(\"SavedModels\", \"ConvLSTMAttentionSouthAfricaWeightedLoss\")\n",
    "MODEL_NAME = \"checkpoint_100.pkl\"\n",
    "SAVEFOLDER.mkdir(parents=True, exist_ok=True)\n",
    "LOAD_MODEL = False\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s:%(message)s')\n",
    "\n",
    "\n",
    "logger = logging.getLogger(\"MSE\")\n",
    "file_handler = logging.FileHandler(SAVEFOLDER / 'mse_log.log')\n",
    "file_handler.setFormatter(formatter)\n",
    "file_handler.setLevel(logging.DEBUG)\n",
    "logger.addHandler(file_handler)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "logger = logging.getLogger(\"GRAD_MSE\")\n",
    "file_handler = logging.FileHandler(SAVEFOLDER / 'grad_mse_log.log')\n",
    "file_handler.setFormatter(formatter)\n",
    "file_handler.setLevel(logging.DEBUG)\n",
    "logger.addHandler(file_handler)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "stream_handler = logging.StreamHandler(sys.stdout)\n",
    "stream_handler.setFormatter(formatter)\n",
    "stream_handler.setLevel(logging.DEBUG)\n",
    "\n",
    "file_handler = logging.FileHandler(SAVEFOLDER / 'log.log')\n",
    "file_handler.setFormatter(formatter)\n",
    "file_handler.setLevel(logging.DEBUG)\n",
    "\n",
    "logger.addHandler(stream_handler)\n",
    "logger.addHandler(file_handler)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "\n",
    "# Dataset parameters\n",
    "default_batch_size = 45\n",
    "default_sequence_length = 30\n",
    "default_sequence_steps = 1\n",
    "default_prediction_steps = 1\n",
    "default_n_predictions = 30\n",
    "\n",
    "# Model parameters\n",
    "kernel_size = (3, 3)\n",
    "padding = ((kernel_size[0] - 1)//2, (kernel_size[1] - 1)//2)\n",
    "frame_size = (20, 40)\n",
    "encoder_in_channels = 32\n",
    "encoder_out_channels = 32\n",
    "hidden_output_network_channels = [32, 32]\n",
    "\n",
    "# Training loop\n",
    "# Start: 53 - 1e-6\n",
    "# Switch: 53 - 1e-3\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 0\n",
    "epochs = 2000\n",
    "save_every = 25\n",
    "n_sequences = 30\n",
    "scheduler = None\n",
    "teacher_forcing_ratio_list: List[float] = [0]*epochs\n",
    "fill_nan = 0\n",
    "train_start = date(2006, 1, 1)\n",
    "train_end = date(2014, 1, 1)\n",
    "validation_end = date(2019, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e06bd9db-6109-425d-8e18-d7912dbe2df2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loss\n",
    "criterion = create_masked_loss_function_diff(nn.MSELoss)\n",
    "\n",
    "regressor = None\n",
    "if LOAD_MODEL:\n",
    "    model, optimizer, last_loss, dataset_parameters, regressor, start_epoch = load_model(\n",
    "        SAVEFOLDER / MODEL_NAME,\n",
    "        DEVICE,\n",
    "        SAVEFOLDER / \"Regression.pkl\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07aa6247-e24d-440b-968d-2a55d7c0aebf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not LOAD_MODEL:\n",
    "    dataset_parameters = DatasetParameters(\n",
    "        batch_size = default_batch_size,\n",
    "        sequence_length = default_sequence_length,\n",
    "        sequence_steps = default_sequence_steps,\n",
    "        prediction_steps = default_prediction_steps,\n",
    "        fill_nan = fill_nan,\n",
    "        train_start = train_start,\n",
    "        train_end = train_end,\n",
    "        validation_end = validation_end,\n",
    "        n_predictions = default_n_predictions,\n",
    "    )\n",
    "    start_epoch = 0\n",
    "\n",
    "    model = setup_model(\n",
    "        in_channels = 1,\n",
    "        encoder_in_channels = encoder_in_channels,\n",
    "        encoder_out_channels = encoder_out_channels,\n",
    "        kernel_size = kernel_size,\n",
    "        padding = padding,\n",
    "        frame_size = frame_size,\n",
    "        hidden_output_network_channels = []\n",
    "    ).to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "try:\n",
    "    with open(SAVEFOLDER / \"Regression.pkl\", 'rb') as file:\n",
    "        regressor = MetaRegression.load(file)\n",
    "except:\n",
    "    regressor = None\n",
    "    \n",
    "train_loader, validation_loader = setup_data(\n",
    "    DATAPATH,\n",
    "    SAVEFOLDER / \"Regression.pkl\",\n",
    "    dataset_parameters, # type: ignore\n",
    "    regressor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03adc3ab-d169-4f79-b1e8-dd0f7d348036",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-13 17:06:33,787:Epoch: 0346/2000 Training Loss: 0.0294326 Validation Loss: 0.0655159\n",
      "2023-07-13 17:07:45,764:Epoch: 0347/2000 Training Loss: 0.0294206 Validation Loss: 0.0654924\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "update_images = PlotOnEpoch(\n",
    "    print_to_file = True,\n",
    "    day_number_first = 0,\n",
    "    day_number_second = 29,\n",
    "    plot_every = 5\n",
    ")\n",
    "for i in range(100):\n",
    "    try:\n",
    "        scheduler = None\n",
    "        losses = train_validation_loop(\n",
    "            model = model, # type: ignore\n",
    "            train_loader = train_loader,\n",
    "            val_loader = validation_loader,\n",
    "            criterion = criterion,\n",
    "            optimizer = optimizer, # type: ignore\n",
    "            num_epochs = epochs,\n",
    "            start_epoch = start_epoch, # type: ignore\n",
    "            device = DEVICE,\n",
    "            update_function = update_images,\n",
    "            path = SAVEFOLDER,\n",
    "            save_n_epochs = save_every,\n",
    "            dataset_parameters = dataset_parameters, # type: ignore\n",
    "            teacher_forcing_ratios = teacher_forcing_ratio_list,\n",
    "            losses = None,\n",
    "            scheduler = scheduler,\n",
    "            n_sequences = n_sequences,\n",
    "        )\n",
    "        plt.close()\n",
    "        break\n",
    "    except ValueError as ex:\n",
    "        plt.close()\n",
    "        if LOAD_MODEL:\n",
    "            raise ex\n",
    "        update_images = PlotOnEpoch(\n",
    "            print_to_file = True,\n",
    "            day_number_first = 0,\n",
    "            day_number_second = 29,\n",
    "            plot_every = 5\n",
    "        )\n",
    "        model = setup_model(\n",
    "            in_channels = 1,\n",
    "            encoder_in_channels = encoder_in_channels,\n",
    "            encoder_out_channels = encoder_out_channels,\n",
    "            kernel_size = kernel_size,\n",
    "            padding = padding,\n",
    "            frame_size = frame_size,\n",
    "            hidden_output_network_channels = []\n",
    "        ).to(DEVICE)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        print(f\"{datetime.now()} | Failed {i} times\", end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faf94e9-2e59-4567-8918-53ce6079558c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    while True:\n",
    "        features, target, mask, _, result_time = next(iter(validation_loader))\n",
    "        # Save time\n",
    "        batch_size = result_time.size(0)\n",
    "        target_times = result_time.numpy()\n",
    "\n",
    "        if torch.any(torch.all(torch.all(mask, dim=3), dim=2)):\n",
    "            continue\n",
    "\n",
    "        # Move to device\n",
    "        features = features.to(DEVICE)\n",
    "        target = target.to(DEVICE)\n",
    "        mask = mask.to(DEVICE)\n",
    "\n",
    "        # Predict\n",
    "        output = model(features, None, n_sequences, 0)\n",
    "        target = target.squeeze(1)\n",
    "        output[mask] = np.nan\n",
    "        target[mask] = np.nan\n",
    "        output = output.detach().cpu().numpy()\n",
    "        target = target.detach().cpu().numpy()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b391c1-b844-4815-83a7-1efc50e7220a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "extent = [5.5, 44.5, -44.5, -25.5]\n",
    "batch_id = 0\n",
    "channel_id = 0\n",
    "day_id = 29\n",
    "plt.figure(figsize=(14,4))\n",
    "plt.imshow(output[batch_id, day_id], origin='lower', cmap='jet')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c7861f-2b16-40d7-93b4-5a8fae442928",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_pred_title_multi(dataset_parameters: DatasetParameters, n_predictions: int):\n",
    "    return f\"{n_predictions * dataset_parameters.prediction_steps} days predictions using {dataset_parameters.sequence_length} day(s) of data\\nwith {dataset_parameters.sequence_steps - 1} day(s) inbetween\"\n",
    "\n",
    "def get_pred_title(dataset_parameters: DatasetParameters, n_predictions: int):\n",
    "    return get_pred_title_multi(dataset_parameters, n_predictions).replace('\\n', ' ')\n",
    "\n",
    "idx = 0\n",
    "day_prediction = 29\n",
    "\n",
    "vmin = -0.75\n",
    "vmax = 0.75\n",
    "cmap = 'jet'\n",
    "\n",
    "vmin_diff = -0.3\n",
    "vmax_diff = 0.3\n",
    "\n",
    "diffs = target - output\n",
    "diff_data = diffs[idx, day_prediction]\n",
    "diff_vector = diff_data[~np.isnan(diff_data)].flatten()\n",
    "rmse = np.sqrt(diff_vector @ diff_vector / len(diff_vector))\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(16,10))\n",
    "im_target = axes[0].imshow(target[idx, day_prediction], origin='lower', extent=extent, vmin=vmin, vmax=vmax, cmap=cmap)\n",
    "im_pred = axes[1].imshow(output[idx, day_prediction], origin='lower', extent=extent, vmin=vmin, vmax=vmax, cmap=cmap)\n",
    "im_diff = axes[2].imshow(diff_data, origin='lower', extent=extent, vmin=vmin_diff, vmax=vmax_diff, cmap=cmap)\n",
    "\n",
    "axes[0].set_title(f\"Target {target_times[idx, day_prediction]} (Validation set)\")\n",
    "axes[1].set_title(get_pred_title(dataset_parameters, day_prediction + 1))\n",
    "axes[2].set_title(f\"Target - Prediction (RMSE = {rmse*100:.2f}cm)\")\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    ax.set_ylabel(\"Latitude\")\n",
    "    ax.set_xlabel(\"Longitude\")\n",
    "\n",
    "caxs = []\n",
    "caxs.append(fig.colorbar(im_target))\n",
    "caxs.append(fig.colorbar(im_pred))\n",
    "caxs.append(fig.colorbar(im_diff))\n",
    "\n",
    "for cax in caxs:\n",
    "    cax.ax.set_ylabel(\"SLA [m]\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeee5773-2f67-41c5-81e1-89d7520024a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.animation\n",
    "import matplotlib\n",
    "\n",
    "plt.rcParams[\"animation.html\"] = \"jshtml\"\n",
    "matplotlib.rcParams['animation.embed_limit'] = 2**128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e80a7a1-473d-4a8c-86ee-74d163d117ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.ioff()\n",
    "fig, axes = plt.subplots(3, 1, figsize=(16, 14))\n",
    "vmin = -0.75\n",
    "vmax = 0.75\n",
    "cmap = 'jet'#cmc.vik\n",
    "\n",
    "idx = 0\n",
    "vmin_diff = -0.3\n",
    "vmax_diff = 0.3\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    ax.set_ylabel(\"Latitude\")\n",
    "    ax.set_xlabel(\"Longitude\")\n",
    "\n",
    "diff_data = diffs[idx, 0]\n",
    "diff_vector = diff_data[~np.isnan(diff_data)].flatten()\n",
    "rmse = np.sqrt(diff_vector @ diff_vector / len(diff_vector))\n",
    "\n",
    "im_target = axes[0].imshow(target[idx, 0], origin='lower', extent=extent, vmin=vmin, vmax=vmax, cmap=cmap)\n",
    "im_pred = axes[1].imshow(output[idx, 0], origin='lower', extent=extent, vmin=vmin, vmax=vmax, cmap=cmap)\n",
    "im_diff = axes[2].imshow(diff_data, origin='lower', extent=extent, vmin=vmin_diff, vmax=vmax_diff, cmap=cmap)\n",
    "\n",
    "axes[0].set_title(f\"Target {target_times[idx, day_prediction]} (Validation set)\")\n",
    "axes[1].set_title(get_pred_title(dataset_parameters, 1))\n",
    "axes[2].set_title(f\"Target - Prediction (RMSE = {rmse*100:.2f}cm)\")\n",
    "caxs = []\n",
    "caxs.append(fig.colorbar(im_target))\n",
    "caxs.append(fig.colorbar(im_pred))\n",
    "caxs.append(fig.colorbar(im_diff))\n",
    "\n",
    "for cax in caxs:\n",
    "    cax.ax.set_ylabel(\"SLA [m]\")    \n",
    "\n",
    "def animate(t):\n",
    "    plt.cla()\n",
    "    diff_data = diffs[idx, t]\n",
    "    diff_vector = diff_data[~np.isnan(diff_data)].flatten()\n",
    "    rmse = np.sqrt(diff_vector @ diff_vector / len(diff_vector))\n",
    "    \n",
    "    im_target = axes[0].imshow(target[idx, t], origin='lower', extent=extent, vmin=vmin, vmax=vmax, cmap=cmap)\n",
    "    im_pred = axes[1].imshow(output[idx, t], origin='lower', extent=extent, vmin=vmin, vmax=vmax, cmap=cmap)\n",
    "    im_diff = axes[2].imshow(diff_data, origin='lower', extent=extent, vmin=vmin_diff, vmax=vmax_diff, cmap=cmap)\n",
    "    \n",
    "    axes[0].set_title(f\"Target {target_times[idx, day_prediction]} (Validation set)\")\n",
    "    axes[1].set_title(get_pred_title(dataset_parameters, t + 1))\n",
    "    axes[2].set_title(f\"Target - Prediction (RMSE = {rmse*100:.2f}cm)\")\n",
    "\n",
    "anim  = matplotlib.animation.FuncAnimation(fig, animate, frames=29)\n",
    "\n",
    "\n",
    "\n",
    "anim.save(SAVEFOLDER / f'{SAVEFOLDER.name}.gif')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d3c624-6ba6-4e40-8ff0-fd1902ba7e93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gif_file = (SAVEFOLDER / f'{SAVEFOLDER.name}.gif').as_posix()\n",
    "display.Image(open(gif_file,'rb').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d871c9-cd73-4909-a67f-981aa87b7b3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
